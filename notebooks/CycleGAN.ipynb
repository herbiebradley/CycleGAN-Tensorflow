{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/herbiebradley/CycleGAN-Tensorflow/blob/master/notebooks/CycleGAN.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "bqIvL-F8LZSN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B4ef9iNfLeiE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test how much GPU RAM on Google Colab\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fL3Utq82bnpn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Hyperparameters"
      ]
    },
    {
      "metadata": {
        "id": "i_HEQcq1bnHi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0002\n",
        "batch_size = 1 # Set batch size to 4 or 16 if training multigpu\n",
        "img_size = 256\n",
        "cyc_lambda = 10\n",
        "epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8J17xVLWbivH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load Datasets"
      ]
    },
    {
      "metadata": {
        "id": "ja2qqCmpZEyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "222517e0-44cd-4b78-cf74-d681e90113e3"
      },
      "cell_type": "code",
      "source": [
        "path_to_zip = tf.keras.utils.get_file('horse2zebra.zip',\n",
        "                                      cache_subdir=os.path.abspath('.'),\n",
        "                                      origin='https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip', \n",
        "                                      extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'horse2zebra/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\n",
            "116875264/116867962 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fAjtU5pUZLMq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_image(image_file, is_train):\n",
        "    image = tf.read_file(image_file)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize_images(image, [256, 256])\n",
        "    image = (image / 127.5) - 1\n",
        "  #if is_train:\n",
        "    # random jittering\n",
        "    \n",
        "    # resizing to 286 x 286 x 3\n",
        "    #input_image = tf.image.resize_images(input_image, [286, 286], \n",
        "                                        #align_corners=True, \n",
        "                                        #method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    #real_image = tf.image.resize_images(real_image, [286, 286], \n",
        "                                        #align_corners=True, \n",
        "                                        #method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    \n",
        "    # randomly cropping to 256 x 256 x 3\n",
        "    #stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "    #cropped_image = tf.random_crop(stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "    #input_image, real_image = cropped_image[0], cropped_image[1]\n",
        "\n",
        "    #if np.random.random() > 0.5:\n",
        "      # random mirroring\n",
        "     # input_image = tf.image.flip_left_right(input_image)\n",
        "     # real_image = tf.image.flip_left_right(real_image)\n",
        "  #else:\n",
        "    #input_image = tf.image.resize_images(input_image, size=[IMG_HEIGHT, IMG_WIDTH], \n",
        "     #                                    align_corners=True, method=2)\n",
        "    #real_image = tf.image.resize_images(real_image, size=[IMG_HEIGHT, IMG_WIDTH], \n",
        "     #                                   align_corners=True, method=2)\n",
        "  \n",
        "  # normalizing the images to [-1, 1]\n",
        "  #input_image = (input_image / 127.5) - 1\n",
        "  #real_image = (real_image / 127.5) - 1\n",
        "\n",
        "    return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OelYw0lPa_0C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_datasetA = tf.data.Dataset.list_files(PATH+'trainA/*.jpg')\n",
        "train_datasetA = train_datasetA.shuffle(1067)\n",
        "train_datasetA = train_datasetA.map(lambda x: load_image(x, True))\n",
        "train_datasetA = train_datasetA.batch(batch_size) # Repeat() here?\n",
        "train_datasetA = iter(train_datasetA)\n",
        "\n",
        "train_datasetB = tf.data.Dataset.list_files(PATH+'trainB/*.jpg')\n",
        "train_datasetB = train_datasetB.shuffle(1334)\n",
        "train_datasetB = train_datasetB.map(lambda x: load_image(x, True))\n",
        "train_datasetB = train_datasetB.batch(batch_size) # Repeat() here?\n",
        "train_datasetB = iter(train_datasetB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cu8otYVSMSuD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define CycleGAN architecture"
      ]
    },
    {
      "metadata": {
        "id": "4hwVfj88MPQt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "    \n",
        "        # Small variance in initialization helps with\n",
        "        self.conv1 = tf.keras.layers.Conv2D(32, kernel_size=7, strides=1, kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv3 = tf.keras.layers.Conv2D(128, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "    \n",
        "        x = tf.pad(inputs, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
        "    \n",
        "        x = self.conv1(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training) # Implement instance norm to more closely match orig. paper (momentum=0.1)?\n",
        "        x = tf.nn.relu(x)\n",
        "    \n",
        "        x = self.conv2(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = tf.nn.relu(x)\n",
        "    \n",
        "        x = self.conv3(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = tf.nn.relu(x)\n",
        "    \n",
        "        return x\n",
        "  \n",
        "  \n",
        "class Residual(tf.keras.Model):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(Residual, self).__init__()\n",
        "    \n",
        "        self.conv1 = tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(128, kernel_size=3, strides=1, kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "    \n",
        "        x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n",
        "    \n",
        "        x = self.conv1(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = tf.nn.relu(x)\n",
        "    \n",
        "        x = tf.pad(x, [[0, 0], [1, 1], [1, 1], [0, 0]], \"REFLECT\")\n",
        "    \n",
        "        x = self.conv2(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "    \n",
        "        x = tf.add(x, inputs)\n",
        "\n",
        "        return x\n",
        "\n",
        "    \n",
        "class Decoder(tf.keras.Model):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "    \n",
        "        self.conv1 = tf.keras.layers.Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv2 = tf.keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv3 = tf.keras.layers.Conv2D(3, kernel_size=7, strides=1, kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "    \n",
        "    def call(self, inputs, training=True):\n",
        "    \n",
        "        x = self.conv1(inputs)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = tf.nn.relu(x)\n",
        "    \n",
        "        x = tf.pad(x, [[0, 0], [3, 3], [3, 3], [0, 0]], \"REFLECT\")\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = tf.nn.tanh(x) # Add 1 and multiply by 127.5 to put img in range [0, 255]?\n",
        "    \n",
        "        return x\n",
        "  \n",
        "  \n",
        "class Generator(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, img_size=256, skip=False):\n",
        "        super(Generator, self).__init__()\n",
        "    \n",
        "        self.img_size = img_size\n",
        "        self.skip = skip #TODO: Add skip\n",
        "    \n",
        "        self.encoder = Encoder()\n",
        "        if(img_size == 128):\n",
        "            self.res1 = Residual()\n",
        "            self.res2 = Residual()\n",
        "            self.res3 = Residual()\n",
        "            self.res4 = Residual()\n",
        "            self.res5 = Residual()\n",
        "            self.res6 = Residual()\n",
        "        else:\n",
        "            self.res1 = Residual()\n",
        "            self.res2 = Residual()\n",
        "            self.res3 = Residual()\n",
        "            self.res4 = Residual()\n",
        "            self.res5 = Residual()\n",
        "            self.res6 = Residual()\n",
        "            self.res7 = Residual()\n",
        "            self.res8 = Residual()\n",
        "            self.res9 = Residual()\n",
        "        self.decoder = Decoder()\n",
        "  \n",
        "    @tf.contrib.eager.defun\n",
        "    def call(self, inputs, training=True):\n",
        "    \n",
        "        x = self.encoder(inputs, training)\n",
        "        if(img_size == 128):\n",
        "            x = self.res1(x, training)\n",
        "            x = self.res2(x, training)\n",
        "            x = self.res3(x, training)\n",
        "            x = self.res4(x, training)\n",
        "            x = self.res5(x, training)\n",
        "            x = self.res6(x, training)\n",
        "        else:\n",
        "            x = self.res1(x, training)\n",
        "            x = self.res2(x, training)\n",
        "            x = self.res3(x, training)\n",
        "            x = self.res4(x, training)\n",
        "            x = self.res5(x, training)\n",
        "            x = self.res6(x, training)\n",
        "            x = self.res7(x, training)\n",
        "            x = self.res8(x, training)\n",
        "            x = self.res9(x, training)\n",
        "        x = self.decoder(x, training)\n",
        "      \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G--PW3hAw1tL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "  \n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=4, strides=2, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv3 = tf.keras.layers.Conv2D(256, kernel_size=4, strides=2, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv4 = tf.keras.layers.Conv2D(512, kernel_size=4, strides=1, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "        self.conv5 = tf.keras.layers.Conv2D(1, kernel_size=4, strides=1, padding='same', kernel_initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "      \n",
        "        self.leaky = tf.keras.layers.LeakyReLU(0.2)\n",
        "  \n",
        "    @tf.contrib.eager.defun\n",
        "    def call(self, inputs, training=True):\n",
        "    \n",
        "        x = self.conv1(inputs)\n",
        "        x = self.leaky(x)\n",
        "    \n",
        "        x = self.conv2(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = self.leaky(x)\n",
        "    \n",
        "        x = self.conv3(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = self.leaky(x)\n",
        "    \n",
        "        x = self.conv4(x)\n",
        "        x = tf.contrib.layers.instance_norm(x, epsilon=1e-05, trainable=training)\n",
        "        x = self.leaky(x)\n",
        "    \n",
        "        x = self.conv5(x)\n",
        "        #x = tf.nn.sigmoid(x) # use_sigmoid = not lsgan\n",
        "    \n",
        "     return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AD7mjyEmimmw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Loss functions"
      ]
    },
    {
      "metadata": {
        "id": "5-rUriDrHJdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def discriminator_loss(disc_of_real_output, disc_of_gen_output, lsgan=True):\n",
        "  \n",
        "    if lsgan: # Use least squares loss\n",
        "        real_loss = tf.reduce_mean(tf.squared_difference(disc_of_real_output, 1))\n",
        "        generated_loss = tf.reduce_mean(tf.square(disc_of_gen_output))\n",
        "    \n",
        "        total_disc_loss = (real_loss + generated_loss) * 0.5 # 0.5 slows down rate that D learns compared to G\n",
        "    else: # Use vanilla GAN loss\n",
        "        real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.ones_like(disc_of_real_output), logits = disc_of_real_output)\n",
        "        generated_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.zeros_like(disc_of_gen_output), logits = disc_of_gen_output)\n",
        "\n",
        "        total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "    return total_disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Phemm-YIHMKu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator_loss(disc_of_gen_output, lsgan=True):\n",
        "    if lsgan: # Use least squares loss\n",
        "        gen_loss = tf.reduce_mean(tf.squared_difference(disc_of_gen_output, 1))\n",
        "    else: # Use vanilla GAN loss\n",
        "        gen_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels = tf.ones_like(disc_generated_output), logits = disc_generated_output) \n",
        "        #l1_loss = tf.reduce_mean(tf.abs(target - gen_output)) # Look up pix2pix loss\n",
        "    return gen_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oebK4Sxrt6A4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cycle_consistency_loss(data_A, data_B, reconstructed_data_A, reconstructed_data_B, cyc_lambda=10):\n",
        "    loss = tf.reduce_mean(tf.abs(data_A - reconstructed_data_A) + tf.abs(data_B - reconstructed_data_B))\n",
        "    return cyc_lambda * loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7RG-nATmkIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "discA = Discriminator()\n",
        "discB = Discriminator()\n",
        "genA2B = Generator()\n",
        "genB2A = Generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MrCYk0fsuCF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "discA_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
        "discB_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
        "genA2B_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
        "genB2A_optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hSWozfzzA2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3J3gkVT-oGoV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_images(fake_A, fake_B):\n",
        "    plt.figure(figsize=(15,15))\n",
        "    fake_A = tf.reshape(fake_A, [256, 256, 3])\n",
        "    fake_B = tf.reshape(fake_B, [256, 256, 3])\n",
        "    display_list = [fake_A, fake_B]\n",
        "    title = ['Generated A', 'Generated B']\n",
        "    for i in range(2):\n",
        "        plt.subplot(1, 2, i+1)\n",
        "        plt.title(title[i])\n",
        "        # getting the pixel values between [0, 1] to plot it.\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-k1YOAtbi28X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(train_datasetA, train_datasetB, epochs, lsgan=True, cyc_lambda=10):  \n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        for i in range(1334):\n",
        "\n",
        "        with tf.GradientTape() as genA2B_tape, tf.GradientTape() as genB2A_tape, \\\n",
        "             tf.GradientTape() as discA_tape, tf.GradientTape() as discB_tape:\n",
        "            try:\n",
        "            # Next training minibatches, default size 1\n",
        "            trainA = next(train_datasetA)\n",
        "            trainB = next(train_datasetB)\n",
        "            except tf.errors.OutOfRangeError:\n",
        "                print(\"Error, run out of data\")\n",
        "                break\n",
        "        \n",
        "            genA2B_output = genA2B(trainA, training=True)\n",
        "            genB2A_output = genB2A(trainB, training=True)\n",
        "        \n",
        "            generate_images(genB2A_output, genA2B_output)\n",
        "        \n",
        "            discA_real_output = discA(trainA, training=True)\n",
        "            discB_real_output = discB(trainB, training=True)\n",
        "        \n",
        "            discA_fake_output = discA(genB2A_output, training=True)\n",
        "            discB_fake_output = discB(genA2B_output, training=True)\n",
        "        \n",
        "            reconstructedA = genB2A(genA2B_output, training=True)\n",
        "            reconstructedB = genA2B(genB2A_output, training=True)\n",
        "        \n",
        "            # Use history buffer of 50 for disc loss\n",
        "            discA_loss = discriminator_loss(discA_real_output, discA_fake_output, lsgan=lsgan)\n",
        "            discB_loss = discriminator_loss(discB_real_output, discB_fake_output, lsgan=lsgan)\n",
        "\n",
        "            genA2B_loss = generator_loss(discB_fake_output, lsgan=lsgan) + \\\n",
        "                      cycle_consistency_loss(trainA, trainB, reconstructedA, reconstructedB, cyc_lambda=cyc_lambda)\n",
        "            genB2A_loss = generator_loss(discA_fake_output, lsgan=lsgan) + \\\n",
        "                      cycle_consistency_loss(trainA, trainB, reconstructedA, reconstructedB, cyc_lambda=cyc_lambda)\n",
        "\n",
        "        genA2B_gradients = genA2B_tape.gradient(genA2B_loss, genA2B.variables)\n",
        "        genB2A_gradients = genB2A_tape.gradient(genB2A_loss, genB2A.variables)\n",
        "      \n",
        "        discA_gradients = discA_tape.gradient(discA_loss, discA.variables)\n",
        "        discB_gradients = discB_tape.gradient(discB_loss, discB.variables)\n",
        "\n",
        "        genA2B_optimizer.apply_gradients(zip(genA2B_gradients, genA2B.variables))\n",
        "        genB2A_optimizer.apply_gradients(zip(genB2A_gradients, genB2A.variables))\n",
        "      \n",
        "        discA_optimizer.apply_gradients(zip(discA_gradients, discA.variables))\n",
        "        discB_optimizer.apply_gradients(zip(discB_gradients, discB.variables))\n",
        "      \n",
        "        print(i)\n",
        "        display.clear_output(wait=True)\n",
        "\n",
        "    # saving (checkpoint) the model every epoch\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1, time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "naOHhGVw3c9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "626eadde-edeb-415b-bc4f-07adbc1c514b"
      },
      "cell_type": "code",
      "source": [
        "train(train_datasetA, train_datasetB, epochs=1, lsgan=True, cyc_lambda=cyc_lambda)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}